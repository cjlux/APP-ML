{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning avec les modules Python tensorflow2/keras :\n",
    "\n",
    "# Entraînement / exploitation d'un réseau de neurones convolutif pour la reconnaissance de chiffres manuscrits\n",
    "\n",
    "version 2.1 du 21 mai 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<span style=\"color:brown;font-family:arial;font-size:normal\"> \n",
    "    Il est fondamental d'utiliser un <span style=\"font-weight:bold;\">Environnement Virtuel Python</span> (EVP) pour chaque projet Python important : l'EVP permet de maîtriser pour chaque projet les versions de l'interpréteur Python et des modules \"sensibles\" (comme tensorflow par exemple).</span></div>\n",
    "\n",
    "Les <i>notebooks</i> de l'APP-ML doivent être chargés dans un processus `jupyter notebook` lancé dans l'EVP <b><span style=\"color: rgb(200, 51, 102);\">minfo_ml</span></b> créé en suivant la procédure du document `Consignes.pdf`. Ils doivent être travaillés dans l'ordre :\n",
    "\n",
    "- `ML1_MNIST.ipynb` : vérifier le bon fonctionnement de l’EVP <b><span style=\"color: rgb(200, 51, 102);\">minfo_ml</span></b>, charger et utiliser les données de la banque MNIST (images et labels).\n",
    "- `ML2_DNN.ipynb` : construire un réseau dense, l’entraîner avec les données de la banque MNIST et afficher ses performances.\n",
    "- `ML3_DNN_suite.ipynb` : charger un réseau dense entraîné et l’exploiter avec les données de test  MNIST.\n",
    "- `ML4_CNN.ipynb` : construire un réseau convolutif, l’entraîner avec la banque MNIST, afficher ses performances et à l'exploiter avec les données de test.\n",
    "    \n",
    "**Les notebooks `ML1_MNIST`, `ML2_DNN` et `ML3_DNN_suite` doivent être travaillés avant celui-ci.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectifs d'apprentissages visés :\n",
    "- Apprendre le fonctionnement d'un réseau de neurones convolutif.\n",
    "- Savoir construire un réseau de neurones convolutif à l'aide du module **keras**, utilisé comme interface du module **tensorflow**.\n",
    "- Savoir entraîner le réseau à classifier les images du MNIST.\n",
    "- Savoir exploiter le réseau entraîné."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/ Les Réseaux de Neurones Convolutifs (RNC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principes généraux\n",
    "\n",
    "Les Réseaux de Neurones Convolutifs (RNC, en anglais *CNN* :*Convolutionnal Neural Network*) proposent des structures particulièrement efficaces pour l'analyse du contenu des images. Pour cela les RNC mettent en oeuvre des traitements et une architecture et bien spécifiques :\n",
    "- l'extraction des caractéristiques des images (*features*) à l'aide de filtres convolutifs,\n",
    "- la réduction avec des filtres de *pooling* de la quantité d'information générée par les nombreux filtres de convolution,\n",
    "- une architecture qui empile des couches \"convolution > activation > pooling...\" chargées d'extraire les caractéristiques de l'image qui sont au final applaties et envoyées en entrée d'un réseau dense chargé de l'étape de classification.\n",
    "\n",
    "Dans la suite, nous allons construire un RNC inspiré du réseau `LeNet5`, un des premiers RNC proposé par Yann LeCun *et al.* dans les années 90 pour la reconnaisance des images MNIST :\n",
    "\n",
    "<p style=\"text-align:center; font-style:italic; font-size:12px;\">\n",
    "    <img src=\"img/LeNet5.png\" ><br>\n",
    "    [Lecun, Y.; Bottou, L.; Bengio, Y.; Haffner, P. (1998). \"Gradient-based learning applied to document recognition\". Proceedings of the IEEE. 86 (11): 2278–2324. doi:10.1109/5.726791.]\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des caractéristiques d'une image avec un filtre de convolution\n",
    "\n",
    "La convolution d'une image par un filtre (aussi appelé noyau, *kernel*) consiste à déplacer une _petite fenêtre 2D_ ( 3x3, 5x5 ....) sur les pixels de l'image et à calculer à chaque fois le produit tensoriel contracté (somme des produits terme à terme) entre les élements du filtre et les pixels de l'image délimitée par la fenêtre du filtre.<br>\n",
    "\n",
    "L'animation ci-dessous illustre la convolution d'une image 5x5 par un filtre 3x3 sans *padding* sur les bords : on obtient une nouvelle image plus petite de 3x3 pixels<br>\n",
    "<p style=\"text-align:center; font-style:italic; font-size:12px;\">\n",
    "    <img src=\"img/filter_3x3.png\" width=\"80\" style=\"display:inline-block;\">\n",
    "    <img src=\"img/Convolution_schematic.gif\" width=\"300\" style=\"display:inline-block;\"><br>\n",
    "    [crédit image : <a href=\"http://deeplearning.stanford.edu/tutorial\">Stanford deep learning tutorial</A>]\n",
    "</p>\n",
    "\n",
    "Pour conserver la taille de l'image d'entrée, on peut utiliser la technique du *padding* pour ajouter de nouvelles données sur les bords de l'image (par dupplication des données sur les bords, ou ajout de lignes et colonnes de 0... par exemple) : \n",
    "\n",
    "<p style=\"text-align:center; font-style:italic; font-size:12px;\">\n",
    "    <img src=\"img/padding.gif\" width=\"350\"><br>\n",
    "    [crédit image : <a href=\"https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2\"> Arden Dertat</a> ]\n",
    "</p>\n",
    "\n",
    "Le but de la convolution est d'extraire des caractéristiques particulières présentes dans l'image source : on parle de \"carte des caractéristiques\" (*feature map*) pour désigner l'image produite par l'opération de convolution. L'état de l'art conduit à utiliser plusieurs filtres convolutifs pour extraire des caractéristiques différentes : on peut avoir jusqu'à plusieurs dizaines de filtres convolutifs dans un même couche du réseau qui génèrent chacun une _feature map_, d'où une augmentation des données crées par ces opérations de convolution...\n",
    "\n",
    "#### Exemples d'extraction de caractéristiques avec des filtres convolutifs connus (filtre de [Prewitt](https://fr.wikipedia.org/wiki/Filtre_de_Prewitt)):\n",
    "\n",
    "À titre d'exemple, la figure ci-dessous montre les 4 *features maps* obtenues en convoluant une image MNIST (un chiffre 7) avec 4 filtres 3x3 bien connus en traitement d'image (filtres de Prewitt pour l'extraction de contours):\n",
    "\n",
    "<p style=\"text-align:center; font-style:italic; font-size:12px;\">\n",
    "    <img src=\"img/7_mnist_4_filtres.png\" width=\"500\"><br>\n",
    "    [crédit image : JLC]\n",
    "</p>\n",
    "\n",
    "On voit que ces filtres agissent comme des filtres de détection de contour : dans les images de sortie, les pixels les plus blancs constituent ce que les filtres ont détecté :\n",
    "- les filtre (a) et (c) détectent des contours horizontaux inférieurs et supérieurs,\n",
    "- les filtre (b) et (d) détectent des contours verticaux droite et gauche.\n",
    "\n",
    "Ces exemples très simples permettent de comprendre comment fonctionne l'extraction des *features* d'une image par filtrage convolutif. Dans les réseaux convolutifs les valeusr des éléments des filtres de convolution sont appris par le réseau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cas général : images RGB traitée par plusieurs filtres de convolution\n",
    "\n",
    "Dans le cas général où les images correspondent à des tableaux 3D (la troisième dimension étant pour les 3 couleurs R(ed), G(reeen) &  B(lue)), le filtre de convolution est lui aussi un tableau 3D. L'opération reste identique au cas 1D : pour une position du filtre 3D sur l'image, le produit tensoriel contracté du filtre avec le sous-tableau 3D correspondant dans l'image fournit un nombre scalaire, et le balayage du procédé sur toute l'image donne la matrice des caractéristiques (*feature map*) de l'image. \n",
    "\n",
    "Par exemple si l'on utilise 10 filtres de convolution 5x5 (10 tableaux de dimensions (5,5,3)) pour traiter (avec  _padding_) une image RGB de 32x32 pixels (tableau de dimensions (32,32,3), on obtient une *feature maps*  de dimensions (32,32,10), soit 10240 termes alors que l'image source n'en a que 1024 !\n",
    "\n",
    "<p style=\"text-align:center; font-style:italic; font-size:12px;\">\n",
    "    <img src=\"img/conv_3D_10.png\" width=\"350\"><br>\n",
    "    [crédit image : <a href=\"https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2\"> Arden Dertat</a> ]\n",
    "</p>\n",
    "\n",
    "$\\leadsto$ Pour réduire la quantité d'information générée par les filtres de convolution sans perdre trop d'information, la convolution est toujours suivie d'une opération de *pooling*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Du filtre convolutif à la couche de neurones convolutifs\n",
    "\n",
    "L'intégration du filtrage convolutif dans la structure du réseau de neurones donne l'organisation des calculs  suivante :\n",
    "\n",
    "- Chaque filtre convolutif possède les mêmes coefficients pour les 3 couleurs : pour le réseau LeNet5 par exemple, chacun des 6 filtres 5x5x3 de la première couche possède seulement 25 coefficients, identiques pour les couleurs R, G & B.\n",
    "\n",
    "- Chaque unité (neurone convolutif) d'une *feature map* de la couche C1 reçoit 75 pixels (25 pixels rouges $R_i$, 25 pixels vert $G_i$ et 25 pixels bleus $B_i$) délimités par la position du filtre convolutif dans l'image source.\n",
    "\n",
    "- Le neurone $k$ d'une *feature map* calcule une sortie $y_k = F_a(\\sum_{i=1}^{25}{\\omega_i(R_i + G_i + B_i) - b_k})$, où $b_k$ est le biais du neurone $k$ et $F_a$ la fonction d'activation (très souvent `relu`).\n",
    "\n",
    "- pour les 6 filtres convolutifs de la couche C1, on a donc  6 x (25 + 1) paramètres, soit 156 paramètres inconnus pour cette couche qui seront déterminés par entraînement du réseau.\n",
    "\n",
    "Le même schéma est utilisé dans toutes les couches convoltionnelles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le *pooling*\n",
    "\n",
    "Le *pooling* vise à réduire la quantité de données à traiter. Comme pour l'opération de convolution, on déplace un filtre sur les éléments du tableau *feature map*  et à chaque position du filtre sur le tableau, on calcule un nombre représentant tous les éléments sélectionnés dans le filtre (par exemple la valeur maximale, ou la moyenne....). Mais contrairement à la convolution, on déplace le filtre sans recouvrement.<br>\n",
    "Dans l'exemple simplifié ci-dessous, le filtre *max spool* transforme la matrice 8x8 en une matrice 4x4 qui décrit \"à peu près\" la même information mais avec moins de données :\n",
    "<p style=\"text-align:center; font-style:italic; font-size:12px;\">\n",
    "    <img src=\"img/max_pool_2x2.png\" width=\"350\"><br>\n",
    "    [crédit image : JLC</a> ]\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travail à faire\n",
    "### 1 - Charger et mettre en forme les données MNIST<br>2 - Construire le réseau de neurones convolutif<br>3 - Entraîner le réseau avec test à chaque *epoch*<br>4 - Exploiter le réseau avec les données de test MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des modules Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le module **keras** qui permet une manipulation de haut niveau des objets **tensorflow** est intégré dans le module **tensorflow** (tf) depuis la version 2. <br>\n",
    "La documentation du module **tf.keras** à consulter pour cet APP est ici : https://www.tensorflow.org/api_docs/python/tf/keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supprimer l'affichage des warnings tensorflow:\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import sys, cv2\n",
    "import matplotlib.pyplot as plt\n",
    "print(f\"Python    : {sys.version.split()[0]}\")\n",
    "print(f\"tensorflow: {tf.__version__} incluant keras {keras.__version__}\")\n",
    "print(f\"numpy     : {np.__version__}\")\n",
    "print(f\"OpenCV    : {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incrustation des tracés matplotlib dans le notebook :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Charger et mettre en forme les données MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le travail de chargement des images MNIST a été traité dans le *notebook* `ML1_MNIST.ipynb` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données du MNIST :\n",
    "(im_train, lab_train), (im_test, lab_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Définir les paramètres importants :\n",
    "nb_im_test  = im_test.shape[0]     # nombre d'images de test \n",
    "nb_pixel    = im_test[0].size      # nombre d'éléments (des pixels) de la première image de test \n",
    "nb_classe   = len(set(lab_test))   # nombre de classe à identifier (les 10 chiffres de 0 à 9)\n",
    "\n",
    "print(f\"{nb_im_test} images de test\")\n",
    "print(f\"{nb_pixel} pixels dans chaque image\")\n",
    "print(f\"{nb_classe} classes à reconnaître (les chiffres de 0 à 9)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en forme des données d'entrée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les couches convolutionnelles du module *kera*s attendent par défaut des tableaux à 4 dimensions `(batch_size, height, width, depth)` :\n",
    "- `batch_size` : nombre d'image en entrée,\n",
    "- `height` et `width` : hauteur et largeur des images (en pixels),\n",
    "- `depth` : profondeur des tableaux (`3` pour une image RGB, `1` pour une image en ton de gris).\n",
    "\n",
    "La forme des images MNIST est :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_train.shape, im_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut donc rajouter une dimension (égale à `1`) après la troisième dimension `28`, par exemple avec la méthode `reshape` des tableaux `ndarray` de numpy.\n",
    "\n",
    "Compléter la cellule suivante pour définir `x_train` et `x_test` obtenus :\n",
    "- en ajoutant une quatrième dimension égale à 1 aux tableaux `im_train` et `im_test` \n",
    "- et en normalisant les valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérification :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_train.shape, x_train.shape, im_test.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise au format *one-hot* des labels MNIST\n",
    "\n",
    "Le travail de transformation en vecteurs *one-hot* des labels MNIST a été traité dans le *notebook* `ML2_DNN.ipynb` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "# 'one-hot' encoding' des labels :\n",
    "y_train = to_categorical(lab_train)\n",
    "y_test  = to_categorical(lab_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Construire le réseau de neurones convolutif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant construire dans la cellule ci-dessous le réseau de neurones **convolutionnel** à l'aide du module **keras**.\n",
    "\n",
    "Comme pour le réseau dense, on crée un objet `model` instance de la classe `Sequential` (cf [tf.keras.Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)), puis on complète `model` de façon  incrémentale en ajoutant chaque couche avec la méthode `add` :\n",
    "\n",
    "- La couche d'entrée de type `InputLayer` (cf [tf.keras.layers.InputLayer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputLayer)) sert à spécifier la forme des données d'entrée.<br>\n",
    "La forme attendue par keras pour des images en entrée est (height, width, depth) : on pourra l'obtenir par exemple avec l'attribut `shape` de n'importe quelle image du tableau `x_train`.<br><br>\n",
    "\n",
    "- Les couches convolutionnelles sont de type `Conv2D` (cf [tf.keras.layers.Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)) :\n",
    "    - les 2 premiers arguments positionnels sont : \n",
    "        - le nombre de filtres de la couche\n",
    "        - la forme du filtre : on peut spécifier  `N` ou `(N,N)` pour spécifier un filtre N x N\n",
    "    - les autres arguments nommés utilisés sont :\n",
    "        - `stride` : le pas du déplacement du filtre de convolution, valeur par défaut :  `stride=1` (équivalent à `(1, 1)`))\n",
    "        - `padding=valid` : pas de padding, ou `padding=same` : sortie de mêmes dimensions que l'entrée (défaut : `valid`)\n",
    "        - `activation` : choix de la fonction d'activation (`'relu'`, '`tanh'`...)<br><br>\n",
    "        \n",
    "- Les couches de *pooling* du réseau LeNet5 historique utilisent un filtre *average pool* qui correspond à la classe `AveragePooling2D`  (cf [tf.keras.layers.AveragePooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D)), mais on aura de meilleurs résultats avec un filtrage *max pool* qui retient la valeur max des pixels dans la fenêtre du filtre (voir la page [tf.keras.layers.MaxPool2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D)). Principaux arguments à utiliser avec `MaxPool2D` :\n",
    "    - `pool_size` :  `N` ou `(N,N)` pour spécifier un filtre N x N (défaut : `(2,2)`)\n",
    "    - `strides` : int, tuple de 2 int, ou None. Si None (valeur par défaut), prend la même valeur que `pool_size`\n",
    "    - `padding` : comme pour la classe `Conv2D`<br><br>\n",
    "\n",
    "- Pour aplatir les 16 *feature maps* 5x5 en un vecteur de 16 * 5 * 5 = 635 éléments, on peut utiliser une couche  `Flatten` (cf [tf.keras.layers.Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten))<br><br>\n",
    "\n",
    "En s'inspirant de la structure du réseau `LeNet5` et des spécifications ci-dessus, on obtient :\n",
    "- couche d'entrée : `Input(shape=x_train[0].shape)` : on utilise l'attribut `shape` de la 1ère image qui vaut (28,28,1).\n",
    "- couche C1 : `Conv2D(6, 5, padding='same', activation='relu', name='C1')`\n",
    "- couche S2 : `MaxPool2D(pool_size=2, name='S2')`\n",
    "- couche C3 : `Conv2D(16, 5, padding='valid', activation='relu', name='C3')`\n",
    "- couche S4 : `MaxPool2D(pool_size=2, name='S4')`\n",
    "- couche d'applissement : `Flatten()`\n",
    "- couche C5 : `Dense(200, activation='relu', name='C5')`\n",
    "- couche F5 : `Dense(84, activation='relu', name='F6'`\n",
    "- couche OUTPUT : `Dense(nb_classe, activation='softmax', name='Output')`\n",
    "\n",
    "Une fois construit, le réseau doit être compilé (au sens de tensorflow) avec la méthode `compile` en utilisant par exemple les arguments :\n",
    "- `loss='categorical_crossentropy'` : choix de la fonction d'erreur (cf [tf.keras.categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_crossentropy))\n",
    "- `optimizer='adam'` : choix de l'optimiseur Adam (cf page [tf.keras.optimizers.Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam))\n",
    "- `metrics=['accuracy']` pour obtenir les données permettant de tracer les courbes de performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D,  MaxPool2D, Flatten\n",
    "\n",
    "# fixer la graine des générateurs aléatoires utilisés par tensorflow:\n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "model = Sequential(name='lenet')\n",
    "\n",
    "# compléter...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec la méthode `summary` de l'objet `model`, faire afficher la description du modèle : noter les valeurs des paramètres..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `tf.keras.utils.plot_model` permet aussi de dessiner la structure du réseau (voir la page [tf.keras.utils.plot_model](https://www.tensorflow.org/api_docs/python/tf/keras/utils/plot_model)).<br>\n",
    "Faire tracer la structure du modèle en ajoutant l'option `show_shapes=True` à l'appel de `model` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarde de l'état initial du  réseau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut sauvegarder l'état initial des poids du réseau non-entraîné (valeurs aléatoires) avec la méthode `Model.save_weights`. <br>\n",
    "Ce sera utile plus loin pour remettre le réseau à son état initial avant de relancer d'autres entraînements :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# vérifier que le dossier 'weights' existe et sinon le créer:\n",
    "if not os.path.exists(\"weights\"): os.mkdir(\"weights\")\n",
    "\n",
    "# sauvegarde des poinds du réseau initial:\n",
    "key = 'conv1_init'\n",
    "model.save_weights('weights/'+key)\n",
    "\n",
    "# afficher les fichiers créés:\n",
    "files=[os.path.join(\"weights\",f) for f in os.listdir(\"weights\") if f.startswith(key)]\n",
    "for f in files: print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque : la méthode `save_weights` utilise la partie `key` du chemin passé en argument pour préfixer les fichiers créés.<br>\n",
    "Lors de la lecture ultérieure des poids du réseau avec la méthode `load_weights` de la classe `Sequential`, il suffira de donner la même information pour retrouver les bons fichiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Entraîner le réseau avec test à chaque *epoch*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consulter au besoin la documentation de la méthode `fit` dans la page [tf.keras.Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential). \n",
    "\n",
    "Compléter la cellule ci-dessous pour entraîner le réseau en utilisant la méthode `fit` de l'objet `model` avec les arguments :\n",
    "- `x_train` : les 60000 images \n",
    "- `y_train` : les 60000 labels encodés *one-hot*.\n",
    "- `epochs=10` : faire 10 fois l'entraînement complet.\n",
    "- `batch_size=64` : découper le jeu des données d'entrée (les 60000 images) en \"lots\" (*batch*) de taille `batch_size`.<br>\n",
    "La mise à jour des poids du réseau est faite au bout de `batch_size` échantillons d'entrée. La valeur de `batch_size` (par défaut est 32) est un paramètre qui influe beaucoup sur la qualité de l'apprentissage : on peut essayer d'autres valeurs (64, 128 ...) et observer comment évoluent les performances d'entraînement).\n",
    "\n",
    "Pour avoir un indicateur réaliste de la qualité du réseau entraîné on teste à chaque `epoch` la précison du réseau entraîné en utilisant les images de test : il faut passer l'agument `validation_data` à la méthode `fit`, en lui affectant le tuple des données de test `(x_test, y_test)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# au cas on on exécute plusieurs fois cette cellule, il faut ré-initialiser \n",
    "# les poids du réseau à leur valeur initiale si on veut comparer les entraînements...\n",
    "key = 'conv1_init'\n",
    "model.load_weights('weights/'+key)  \n",
    "\n",
    "# fixer la graine des générateurs aléatoires utilisés par tensorflow:\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "hist = model.fit(x_train, y_train,\n",
    "                 validation_data=(x_test, y_test),\n",
    "                    batch_size=64,\n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objet `hist` retourné par la méthode `fit` possède un attribut `history` de type dictionnaire dont les clefs `'loss'`, `'accuracy'` contiennent l'évaluation de la fonction de cout et de la précision du réseau à la fin de chaque (*epoch*) avec les données d'entraînement. Les clefs `'val_loss'` et `'val_accuracy'` sont associées aux données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hist.history['loss'])\n",
    "print(hist.history['accuracy'])\n",
    "print(hist.history['val_loss'])\n",
    "print(hist.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracé des courbes `accuracy` et `loss`  de l'entraînement et des test :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `plot_loss_accuracy` du module `utils.tools` (présent dans le répertoire du notebook) permet de tracer les courbes de précision et de perte en utilisant les données stockées dans l'objet `hist`. Faire tracer ces courbes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrêter automatiquement l'entraînement avant *over-fit*\n",
    "\n",
    "Keras propose des outils pour arrêter automatiquement l'apprentissage en surveillant par exemple la croissance de `val_accuracy` ou la décroisance de `val_losss` d'une `epoch` à l'autre (cf le callback  [EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)).\n",
    "\n",
    "On peut ainsi définir une liste de fonctions *callback* que l'on peut passer en argument à la fonction `fit` avec l'agument nommé  `callbacks` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "callbacks_list = [\n",
    "    EarlyStopping(monitor='val_accuracy',  # la grandeur à surveiller\n",
    "                  patience=2,              # accepter que 'val_accuracy' diminue 2 fois en tout\n",
    "                  mode='max',              # arrêter si le paramètre décroît \n",
    "                  restore_best_weights=True,\n",
    "                  verbose=1)\n",
    "]\n",
    "\n",
    "# recharger l'état initial du réseau:\n",
    "key = 'conv1_init'\n",
    "model.load_weights('weights/'+key)  \n",
    "\n",
    "# fixer la graine des générateurs aléatoires utilisés par tensorflow:\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "hist = model.fit(x_train, y_train,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=15, \n",
    "                    batch_size=68, \n",
    "                    callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracer les courbes `loss` et `accuracy` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le réseau convolutionnel tend vers une meilleure précision voisine de 99%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarder les poids du  réseau entraîné"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode `save_weights` de la classe `Sequential`permet d'enregistrer les **poids** du réseau entraïné dans un fichier :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# vérifier que le dossier 'weights' existe et sinon le créer:\n",
    "if not os.path.exists(\"weights\"): os.mkdir(\"weights\")\n",
    "\n",
    "# sauvegarde des poids du réseau entrainé:\n",
    "key = 'conv1_trained'\n",
    "model.save_weights('weights/'+key)\n",
    "\n",
    "# afficher les fichiers créés:\n",
    "files=[os.path.join(\"weights\",f) for f in os.listdir(\"weights\") if f.startswith(key)]\n",
    "for f in files: print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarder la structure du réseau et ses poids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode `save` de la classe `Sequential` permet d'enregistrer **toute la structure et les poids** du réseau entraïné dans un fichier.<br />\n",
    "Ceci permet de recréer plus tard *from scratch* le réseau entrainé pour passer en phase exploitation du réseau par exemple, en utilisant la fonction`tf.keras.models.load_model` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# vérifier que le dossier 'weights' existe et sinon le créer:\n",
    "if not os.path.exists(\"models\"): os.mkdir(\"models\")\n",
    "\n",
    "# sauvegarder structure réseau + poids :\n",
    "key = 'conv1_trained'\n",
    "model.save('models/'+key) \n",
    "\n",
    "# afficher les fichiers créés:\n",
    "files=[os.path.join(\"models\",f) for f in os.listdir(\"models\") if f.startswith(key)]\n",
    "for f in files: print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Exploiter le réseau entraîné : méthode `predict`\n",
    "\n",
    "La méthode `predict` de l'objet `model` permet de calculer les inférences du réseau pour une ou plusieurs entrées (voir la méthode `predict`dans la page [tf.keras.Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#predict)).\n",
    "\n",
    "La cellule ci-dessous montre la mise en oeuvre de la méthode `predict` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 100  # numéro de l'image de test choisie\n",
    "\n",
    "# afficher l'image :\n",
    "from utils.tools import plot_images\n",
    "plot_images(im_test,i,1,1) ; plt.show()\n",
    "\n",
    "# inférence du réseau entrainé pour l'image choisie: \n",
    "rep = model.predict(x_test[i:i+1])      # Attention: x doit être un tableau de matrices...\n",
    "                                        # => x[i] ne convient pas !\n",
    "\n",
    "print(f\"Inférence du réseau pour l'image n° {i} :\\n{rep[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pour rendre plus lisible la sortie du réseau, on peut limiter à 2 chiffre après la virgule l'affichage du tableau numpy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.printoptions(formatter={'float':'{:.2f}'.format}):    \n",
    "    print(f\"Inférence du réseau pour l'image n° {i} arrondie à 2 chiffre :\\n{rep[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode `argmax` des tableaux *ndarray* de *numpy* permet d'obtenir le rang de la valeur maximale :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Le label prédit par le réseau est rep[0].argmax() : {rep[0].argmax()}\")\n",
    "print(f\"Le label associé à l'image choisie est lab_test[{i}] : {lab_test[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilité de la méthode `argmax` de numpy pour décoder le tableau de vecteurs *one-hot* renvoyé par la méthode `predict`\n",
    "\n",
    "Quand on calcule une inférence du réseau `model` avec les images du tableau `x_test` par exemple, on obtient un résultat qui est un tableau de vecteurs *one-hot* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(x_test)\n",
    "print(\"forme du tableau 'results':\", results.shape)\n",
    "print(\"allure des vecteurs du tableau 'result' :\")\n",
    "with np.printoptions(formatter={'float':'{:.2f}'.format}): \n",
    "    print(\"results[0]  :\", results[0])\n",
    "    print(\"results[-1] :\", results[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec l'expression `results.argmax(axe=-1)`, on obtient le tableau des `argmax` de chaque vecteur $\\leadsto$ c'est directement le tableau des chiffres reconnus par le réseau :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferences = results.argmax(axis=-1)\n",
    "print(f\"inferences.shape: {inferences.shape}, inferences.dtype: {inferences.dtype}\")\n",
    "print(f\"contenu du tableau inferences : {inferences}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut comparer le tableau `inférences` et le tableau `lab_test` avec l'operateur `==` (cela a un sens avec les tableaux *ndarray* du module *numpy*) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferences == lab_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en comptant le nombre de `True` dans le résultat, on a directement le nombre d'inférences justes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reponse_ok = (inferences == lab_test)\n",
    "print(f\"nombre de réponses justes : {reponse_ok.sum()} sur {nb_im_test} images de test\")\n",
    "precision = reponse_ok.sum()/nb_im_test*100\n",
    "print(f\"performance du réseau entraîné : {precision} % de réponses justes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Afficher la matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import show_cm\n",
    "help(show_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire afficher la matrice de confusion avec la fonction `show_cm` en lui passant les argumets : le tableau des labels au format *one-hot* `lab_test`, le tableau des labels `results` calculés par le model et la liste des classes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autres ressources intéressantes... des vidéos :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://www.youtube.com/embed/trWrEWfhTVg\" width=\"800\" height=\"450\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe src=\"https://www.youtube.com/embed/trWrEWfhTVg\" width=\"800\" height=\"450\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://www.youtube.com/embed/aircAruvnKk\" width=\"800\" height=\"450\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe src=\"https://www.youtube.com/embed/aircAruvnKk\" width=\"800\" height=\"450\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://www.youtube.com/embed/IHZwWFHWa-w\" width=\"800\" height=\"450\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe src=\"https://www.youtube.com/embed/IHZwWFHWa-w\" width=\"800\" height=\"450\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://www.youtube.com/embed/Ilg3gGewQ5U\" width=\"800\" height=\"450\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe src=\"https://www.youtube.com/embed/Ilg3gGewQ5U\" width=\"800\" height=\"450\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
